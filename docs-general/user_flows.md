# OHLCV collector
OHLCV collector вне общего флоу и автономно работает по расписанию.
Забирает и сохраняет в Raw OHLCV storage данные по интересующим меня символам.
Частота сбора/дополнения данных: примерно 1/3 от таймфрейма.
Набор поддерживаемых таймфреймов:
- 1M (месяц)
- 1w (неделя)
- 1d (день)
- 4h (4 часа)
- 1h (1 час)

# Flows
Перечислены в порядке приоритета и очерёдности реализации:

## Flow 1
По расписанию:
1. OHLCV exporter получает из Raw OHLCV storage временные ряды для заданной монеты с ТФ 1М, сохраняет json в Flow artifacts storage, сохраняет в журнал flow_run метаданные:
  - requested_at
  - created_at
  - symbol
  - timeframe
  - gcs_uri
  - signed_url
  - expires_at
2. Chart exporter обращается к Chart-Img API и получает графики для заданной монеты на ТФ 1М с заданным набором индикаторов (png-файлы, несколько штук за запуск); набор графиков, набор индикаторов и некоторые другие параметры задаются шаблоном; сохраняет графики в Flow artifacts storage, сохраняет в журнал flow_run метаданные:
  - chart_template_id
  - requested_at
  - created_at
  - symbol
  - timeframe
  - gcs_uri
  - signed_url
  - expires_at
3. LLM service забирает по gcs_uri json с OHLCV, а также графики; использует промпт из Prompts storage, параметры модели из Models metadata storage; обращается к LLM; LLM возвращает structured output с аналитическим отчётом; LLM service сохраняет в Reports&Recommendations Storage json с отчётом; сохраняет в журнал flow_run метаданные:
  - requested_at
  - created_at
  - symbol
  - timeframe
  - llm_prompt_id
  - llm_model_id
  - ohlcv_ref (ссылка на использованный ряд OHLCV)
  - chart_refs [] (ссылки на использованные графики)
  - ??? тут вопрос: нужно ли сохранять отчёты не в общее Artifacts storage, а в отдельное хранилище ??? Аргумент за отдельное хранилище - необходимость в будущем делать развитый функционал по проверке ранее сделанных отчётов, для чего придётся много фильтровать отчёты по метаданным, но может быть, и в Cloud Storage с ними тоже будет нормально работать ???
4. Повторить шаг 1, но уже с ТФ 1w
5. Повторить шаг 2, но уже с ТФ 1w
6. Повторить шаг 3, но используя OHLCV и графики с шагов 4-5, а также включив в контекст вызова LLM 1M-отчёт с шага 3.

Результат флоу: json-отчёт 1w сохранён в Artifacts storage или Reports&Recommendations Storage, пользователь уведомлен и может использовать этот отчёт в своей работе (за пределами приложения).

## Flow 2
Запускается по пользовательскому запросу.
Расширяет Flow 1 шагами:
7. Повторить шаг 1 flow 1, но уже с ТФ 1d
8. Повторить шаг 2 flow 1, но уже с ТФ 1d
9. Повторить шаг 3, но используя OHLCV и графики с шагов 7-8, а также включив в контекст вызова LLM 1w-отчёт с шага 6.
10. Повторить шаг 1 flow 1, но уже с ТФ 4h
11. Повторить шаг 2 flow 1, но уже с ТФ 4h
12. Повторить шаг 3, но используя OHLCV и графики с шагов 10-11, а также включив в контекст вызова LLM 1d-отчёт с шага 9.

Промпты и параметры модели для каждого шага могут отличаться, поэтому их целесообразно хранить отдельно.

## Flow 3
Запускается по пользовательскому запросу.
Расширяет flow 2 шагами:
13. LLM service забирает отчёты со всех таймфреймов: 1d и выше. Использует промпт из Prompts storage, параметры модели из Models metadata storage; обращается к LLM; LLM возвращает structured output с торговыми рекомендациями; LLM service сохраняет в Reports&Recommendations Storage json с рекомендациями; сохраняет в журнал flow_run метаданные:
  - requested_at
  - created_at
  - symbol
  - llm_prompt_id
  - llm_model_id
  - signal_strength
  - summary
  - reasoning
  - source_report_id [] (ссылки на отчёты)

Результат флоу: json-рекомендации сохранены в Artifacts storage или Reports&Recommendations Storage, пользователь уведомлен и может использовать эти рекомендации в своей работе (за пределами приложения).

## Flow 4
Расширяет flow 3 шагом, запускаемым ПЕРЕД обращением в LLM storage для построения рекомендации:
- Account data exporter обращается по API к бирже, получает информацию по пользовательскому аккаунту: о доступном депозите, открытых позициях, активных ордерах, сохраняет эту информацию в Artifacts storage, сохраняет в журнал flow_run метаданные
- На шаге 13 LLM service получает доступный депозит, открытые позиции, активные ордера из Artifacts storage, включает их в контекст запроса к LLM

Результат флоу: json-рекомендации уточнены с учётом состояния счёта пользователя.

## Flow 5
Расширяет flow 2-4 тем, что в процессе выполнения анализа или построения рекомендаций LLM может "запросить" дополнительные технические индикаторы, отсутствовавшие в OHLCV и на графиках; в этом случае приложение обращается по API к бирже, получает запрошенные данные (если они доступны) и предоставляет их в LLM.
Это может быть реализовано как LLM-агентская система с function calling'ом.

## Flow 6
Расширяет предыдущие флоу тем, что по расписанию или запросу по API получаются новостные данные и/или фундаментальные индикаторы, которые также включаются в контекст LLM при построении отчётов и рекомендаций.

## Flow 7
Запускается по расписанию.
Постоянно мониторит данные по списку символов (по сути, с заданной периодичностью прогоняет флоу 4-7).
Уведомляет пользователя только в случае, если при очередном прогоне удалось сформировать рекомендацию, содержащую сильные торговые сигналы.